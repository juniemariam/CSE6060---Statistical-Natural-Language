{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Custom Word Embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import brown\n",
    "model = gensim.models.Word2Vec(brown.sents())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('brown.embedding')\n",
    "new_model = gensim.models.Word2Vec.load('brown.embedding')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\JEV\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(new_model['university'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\JEV\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `similarity` (Method will be removed in 4.0.0, use self.wv.similarity() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model.similarity('university','school') > 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.data import find\n",
    "word2vec_sample = str(find('models/word2vec_sample/pruned.word2vec.txt'))\n",
    "model = gensim.models.KeyedVectors.load_word2vec_format(word2vec_sample, binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(model.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(model['university'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.most_similar(positive=['university'], topn = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.doesnt_match('breakfast cereal dinner lunch'.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.most_similar(positive=['woman','king'], negative=['man'], topn = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.most_similar(positive=['Paris','Germany'], negative=['Berlin'], topn = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "labels = []\n",
    "count = 0\n",
    "max_count = 50\n",
    "X = np.zeros(shape=(max_count,len(model['university'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "labels = []\n",
    "count = 0\n",
    "max_count = 50\n",
    "X = np.zeros(shape=(max_count,len(model['university'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for term in model.vocab:\n",
    "    X[count] = model[term]\n",
    "    labels.append(term)\n",
    "    count+= 1\n",
    "    if count >= max_count: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It is recommended to use PCA first to reduce to ~50 dimensions\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=50)\n",
    "X_50 = pca.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using TSNE to further reduce to 2 dimensions\n",
    "from sklearn.manifold import TSNE\n",
    "model_tsne = TSNE(n_components=2, random_state=0)\n",
    "Y = model_tsne.fit_transform(X_50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the scatter plot\n",
    "import matplotlib.pyplot as plt\n",
    "plt.scatter(Y[:,0], Y[:,1], 20)\n",
    "#Add labels\n",
    "for label, x, y in zip(labels, Y[:, 0], Y[:, 1]):\n",
    "    plt.annotate(label, xy = (x,y), xytext = (0, 0), textcoords = 'offset points', size = 10)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use Of default word Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp=spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing from website\n",
    "from urllib import request\n",
    "url=\"http://www.gutenberg.org/files/62304/62304-0.txt\"\n",
    "response=request.urlopen(url)\n",
    "rawtext=response.read().decode('utf8')\n",
    "type(rawtext)\n",
    "doc=nlp(rawtext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.54711723, -1.9657634 ,  0.2217341 , -3.7481773 ,  1.1649952 ,\n",
       "        0.82003343,  3.1833057 ,  1.3274641 ,  0.6739967 , -1.5965436 ,\n",
       "       -1.6797376 , -0.29845873,  1.6415154 ,  1.8445041 , -1.990669  ,\n",
       "        0.5988834 ,  0.36557356,  1.0014813 , -0.2872901 ,  1.5161064 ,\n",
       "        3.033439  , -0.5433321 , -1.7090623 , -2.684139  , -1.3771006 ,\n",
       "        4.3160543 , -0.39623195,  2.1399436 , -1.5976278 , -0.8109217 ,\n",
       "       -0.01566228, -2.1897125 ,  1.8993993 , -2.2924256 ,  0.53279907,\n",
       "        1.0346884 , -1.360132  ,  1.2321562 ,  2.3556318 , -2.3481326 ,\n",
       "        0.6372895 ,  4.0386653 , -1.6353981 ,  1.3072901 , -0.4548158 ,\n",
       "        0.50143105,  2.0086179 , -1.170733  , -0.02461302,  0.38845354,\n",
       "        0.2930492 ,  2.2574885 ,  2.008726  ,  0.2767743 , -3.3642    ,\n",
       "        3.158045  ,  0.4759503 , -3.3558373 , -2.28846   , -2.868757  ,\n",
       "       -1.7053337 , -0.149629  , -1.3066813 , -2.9380534 ,  0.8086827 ,\n",
       "        2.3146083 ,  3.981751  , -0.6188738 , -2.6224663 ,  4.1584663 ,\n",
       "       -0.27914786, -1.9328592 , -2.118707  ,  1.543572  , -1.5318053 ,\n",
       "       -0.25009978,  3.6898909 ,  1.625823  , -1.1249613 , -1.2693954 ,\n",
       "        3.3221662 ,  2.8248892 , -1.5188748 , -0.862022  ,  1.9106407 ,\n",
       "        0.11761621,  0.4570887 , -2.6350183 , -0.86446375,  0.2664957 ,\n",
       "       -0.2370862 , -3.8782396 ,  0.88569415,  0.4801476 ,  0.13499802,\n",
       "        1.647794  ], dtype=float32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the vector for 'text':\n",
    "doc[3].vector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.2334902 , -0.40256122, -0.78241116, -0.7215848 ,  0.8360339 ,\n",
       "       -0.16409647,  1.2739755 ,  0.75103194, -0.05853712, -0.29435676,\n",
       "       -0.12873717, -0.38099372, -0.15153512,  0.24945143, -0.90397596,\n",
       "        0.01044266, -0.40441835, -0.13788924, -0.03983409,  0.56642383,\n",
       "        0.25509375,  0.85622525, -0.217485  , -0.4397096 ,  0.12726183,\n",
       "        0.7110893 ,  0.27750942,  0.24298477,  0.45374662, -0.17743309,\n",
       "       -0.66717607, -0.0933699 , -0.5372219 , -0.65386796, -0.45200068,\n",
       "       -0.10164119,  0.38375252,  0.18838185,  0.03894509,  0.7054388 ,\n",
       "        0.35017535, -0.25892934,  0.41956583, -0.80153257,  0.9959928 ,\n",
       "       -0.02972438, -0.18958187,  0.203635  , -0.00624284,  0.5241773 ,\n",
       "       -0.17431964,  0.15089673,  0.17450866,  0.3888655 , -0.22213805,\n",
       "       -0.04573665,  0.76046556,  0.13938342, -0.5810467 , -0.28338286,\n",
       "        0.04311839, -0.75463355,  0.364408  , -0.33297136, -0.18057045,\n",
       "       -0.2680869 ,  0.75112617, -0.3508736 , -0.02367671,  0.4212896 ,\n",
       "        0.69334835, -0.55498856,  0.23429431, -0.33325908,  0.2891663 ,\n",
       "        0.7747863 ,  0.5775895 , -0.08792231, -0.8549056 , -0.51741576,\n",
       "       -0.1911221 , -0.02828167,  0.08597416,  0.01741872, -0.07029662,\n",
       "       -0.6613308 ,  0.63257265, -0.78694975, -0.8666922 ,  0.72219676,\n",
       "        0.32247296, -0.9530336 , -0.9496497 ,  0.5624327 ,  0.17067406,\n",
       "        0.49143663], dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the mean vector for the entire sentence (useful for sentence classification etc.)\n",
    "doc.vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Once assigned, word embeddings in Spacy are accessed for words and sentences using the .vector attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'spacy.tokens.token.Token' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-7f8c918cd3c4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mvector\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0mvectors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdoc\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-12-7f8c918cd3c4>\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mvector\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0mvectors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdoc\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\gensim\\models\\keyedvectors.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, entities)\u001b[0m\n\u001b[0;32m    353\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_vector\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mentities\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    354\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 355\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mvstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_vector\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mentity\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mentity\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mentities\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    356\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    357\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__contains__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mentity\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'spacy.tokens.token.Token' object is not iterable"
     ]
    }
   ],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "\n",
    "# Load vectors directly from the file\n",
    "model = KeyedVectors.load_word2vec_format('C:/Users/JEV/Downloads/GoogleNews.bin', binary=True)\n",
    "\n",
    "# Access vectors for specific words with a keyed lookup:\n",
    "vector = model['easy']\n",
    "# see the shape of the vector (300,)\n",
    "vector.shape\n",
    "\n",
    "vectors = [model[x] for x in doc]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.similarity('straightforward','easy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.similarity('simple','impossible')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.most_similar('simple')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Gensim provides a number of helper functions to interact with word vector models. Similarity is determined using the cosine distance between two vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
